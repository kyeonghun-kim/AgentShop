import subprocess

try:
    subprocess.run(["playwright", "install", "chromium"], check=True)
except Exception as e:
    print(f"Playwright browser install failed: {e}")

import os
import asyncio
import json
import streamlit as st
from pydantic import create_model, Field
from crawl4ai import (
    AsyncWebCrawler,
    BrowserConfig,
    CrawlerRunConfig,
    CacheMode,
    LLMConfig,
)
from crawl4ai.extraction_strategy import LLMExtractionStrategy
from dotenv import load_dotenv
import os

load_dotenv(".env")

# ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ë³´ì•ˆìƒ .env ì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ê²Œ ì¢‹ìŒ)
PASSWORD = os.getenv("APP_PASSWORD")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")


def password_gate():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if not st.session_state.authenticated:
        st.title("ğŸ” Password Required")
        pw = st.text_input("Enter the password", type="password")
        if pw == PASSWORD:
            st.session_state.authenticated = True
            st.success("Access granted!")
            st.rerun()
        elif pw:
            st.error("Incorrect password")
        st.stop()


password_gate()

# ğŸ§  ì‚¬ìš©ìë¡œë¶€í„° API Key ì…ë ¥ë°›ê¸°
if not OPENAI_API_KEY:
    st.warning("âš ï¸ API keyê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def run_crawler(schema_json: str, url: str, instruction: str, model_choice: str):
    """
    schema_json: Pydantic ëª¨ë¸ì˜ JSON ìŠ¤í‚¤ë§ˆ ë¬¸ìì—´
    url: í¬ë¡¤ë§í•  ëŒ€ìƒ URL
    instruction: ë°ì´í„° ì¶”ì¶œì— ì‚¬ìš©í•  instruction
    # model_choice: ì„ íƒëœ LLM ëª¨ë¸ (ì˜ˆ: "gpt-4o" ë˜ëŠ” "gpt-4o-mini")
    """

    async def main():
        # LLM Extraction Strategy ì„¤ì • (ì„ íƒëœ ëª¨ë¸ ë°˜ì˜)
        llm_strategy = LLMExtractionStrategy(
            llm_config=LLMConfig(provider=f"{model_choice}", api_token=OPENAI_API_KEY),
            schema=schema_json,
            extraction_type="schema",
            instruction=instruction,
            chunk_token_threshold=1000,
            overlap_rate=0.0,
            apply_chunking=True,
            input_format="markdown",
            extra_args={"temperature": 0.0, "max_tokens": 800},
        )

        crawl_config = CrawlerRunConfig(
            extraction_strategy=llm_strategy,
            cache_mode=CacheMode.BYPASS,
            page_timeout=120000,
        )

        browser_cfg = BrowserConfig(
            headless=True, verbose=True, user_agent_mode="random"
        )

        async with AsyncWebCrawler(config=browser_cfg) as crawler:
            result = await crawler.arun(url=url, config=crawl_config)
            if result.success:
                data = json.loads(result.extracted_content)
                return data, llm_strategy
            else:
                return {"error": result.error_message}, None

    return asyncio.run(main())


def main():
    st.title("Dynamic Model & Crawler Example")

    # ë©”ì¸ í™”ë©´: í¬ë¡¤ë§ URL ì…ë ¥
    url = st.text_input("Enter URL to crawl", "https://example.com/products")

    # ì‚¬ì´ë“œë°”: ëª¨ë¸ ìƒì„± ë° extraction instruction ì…ë ¥
    st.sidebar.title("Model & Extraction Settings")

    # Extraction Instruction ì…ë ¥ (ì‚¬ì´ë“œë°”)
    instruction = st.sidebar.text_area(
        "Extraction Instruction",
        "Extract all product objects with 'name' and 'price' from the content.",
    )

    # LLM ëª¨ë¸ ì„ íƒ (ì‚¬ì´ë“œë°”)
    model_choice = st.sidebar.selectbox(
        "Select LLM Model", ["openai/gpt-4o", "openai/gpt-4o-mini"], index=0
    )

    # ì‚¬ì´ë“œë°”: ë™ì  í•„ë“œ ì…ë ¥
    st.sidebar.header("Dynamic Model Fields")
    if "row_count" not in st.session_state:
        st.session_state.row_count = 1
    if "DynamicModel" not in st.session_state:
        st.session_state.DynamicModel = None

    for i in range(1, st.session_state.row_count + 1):
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.text_input(f"Field Name {i}", key=f"field_name_{i}")
        with col2:
            st.text_input(f"Field Type {i}", key=f"field_type_{i}", value="str")

    # "Add Field Pair" ë²„íŠ¼: í•„ë“œ ìŒ ì¶”ê°€
    def add_row():
        st.session_state.row_count += 1

    # "Generate Model" ë²„íŠ¼: ì…ë ¥ëœ í•„ë“œë¡œ Pydantic ëª¨ë¸ ìƒì„±
    def generate_model():
        dynamic_fields = {}
        for i in range(1, st.session_state.row_count + 1):
            field_name = st.session_state.get(f"field_name_{i}", "").strip()
            field_type_str = st.session_state.get(f"field_type_{i}", "").strip()
            if not field_name:
                continue

            # ê°„ë‹¨í•œ íƒ€ì… ë§¤í•‘
            if field_type_str.lower() == "int":
                python_type = int
            elif field_type_str.lower() == "float":
                python_type = float
            elif field_type_str.lower() == "bool":
                python_type = bool
            else:
                python_type = str

            dynamic_fields[field_name] = (
                python_type,
                Field(..., description=f"{field_name} (type: {field_type_str})"),
            )
        if dynamic_fields:
            NewModel = create_model("DynamicModel", **dynamic_fields)
            st.session_state.DynamicModel = NewModel
            st.sidebar.success("Pydantic ëª¨ë¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.sidebar.warning("ìœ íš¨í•œ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. í•„ë“œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")

    st.sidebar.button("Add Field Pair", on_click=add_row)
    st.sidebar.button("Generate Model", on_click=generate_model)

    if st.session_state.DynamicModel:
        st.sidebar.write("**Generated Model Schema**")
        st.sidebar.json(st.session_state.DynamicModel.model_json_schema())

    # ë©”ì¸ í™”ë©´: í¬ë¡¤ëŸ¬ ì‹¤í–‰
    if st.button("Run Crawler"):
        if st.session_state.DynamicModel:
            schema_json = st.session_state.DynamicModel.model_json_schema()
            with st.spinner("Crawling... please wait..."):
                data, strategy = run_crawler(
                    json.dumps(schema_json), url, instruction, model_choice
                )
            if "error" in data:
                st.error(f"Crawling error: {data['error']}")
            else:
                st.success("Crawling completed!")
                st.json(data)
                if strategy:
                    st.write("**Token Usage**")
                    strategy.show_usage()
        else:
            st.warning("ë¨¼ì € ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
